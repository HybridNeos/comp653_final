{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "#from imblearn.over_sampling import SMOTE\n",
    "from math import exp\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "#from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection by correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label                           1.000000\n",
       "rank_incident_severity          0.119142\n",
       "non_violent_rate                0.096296\n",
       "number_of_vehicles_involved     0.078499\n",
       "violent_rate                    0.072924\n",
       "in_state                        0.070108\n",
       "deaths_per_100k                 0.055592\n",
       "rank_insured_education_level    0.050458\n",
       "policy_amt                     -0.049461\n",
       "umbrella_limit                  0.049313\n",
       "csl_amt                        -0.048822\n",
       "incident_hour_of_the_day        0.040186\n",
       "deaths_per_100mil_miles         0.036632\n",
       "witnesses                       0.035485\n",
       "bodily_injuries                 0.028191\n",
       "capital_gains                  -0.024975\n",
       "avg_car_price                   0.013819\n",
       "capital_loss                   -0.013543\n",
       "claim_capital_percent           0.003998\n",
       "months_as_customer             -0.003483\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train_data.csv\").rename({\"deaths_per_100mil_vehicle_miles\": \"deaths_per_100mil_miles\"}, axis=1)\n",
    "df.corr(numeric_only=True)[\"label\"].sort_values(key=lambda x: abs(x), ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>policy_amt</th>\n",
       "      <th>csl_amt</th>\n",
       "      <th>violent_rate</th>\n",
       "      <th>non_violent_rate</th>\n",
       "      <th>deaths_per_100k</th>\n",
       "      <th>deaths_per_100mil_miles</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>policy_amt</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>csl_amt</th>\n",
       "      <td>0.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>violent_rate</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.72</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non_violent_rate</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.73</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deaths_per_100k</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.96</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deaths_per_100mil_miles</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         policy_amt  csl_amt  violent_rate  non_violent_rate  \\\n",
       "policy_amt                      NaN     0.99           NaN               NaN   \n",
       "csl_amt                        0.99      NaN           NaN               NaN   \n",
       "violent_rate                    NaN      NaN           NaN              0.85   \n",
       "non_violent_rate                NaN      NaN          0.85               NaN   \n",
       "deaths_per_100k                 NaN      NaN          0.70              0.83   \n",
       "deaths_per_100mil_miles         NaN      NaN          0.72              0.73   \n",
       "label                           NaN      NaN           NaN               NaN   \n",
       "\n",
       "                         deaths_per_100k  deaths_per_100mil_miles  label  \n",
       "policy_amt                           NaN                      NaN    NaN  \n",
       "csl_amt                              NaN                      NaN    NaN  \n",
       "violent_rate                        0.70                     0.72    NaN  \n",
       "non_violent_rate                    0.83                     0.73    NaN  \n",
       "deaths_per_100k                      NaN                     0.96    NaN  \n",
       "deaths_per_100mil_miles             0.96                      NaN    NaN  \n",
       "label                                NaN                      NaN    NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For my thid party feature, see if they are self correlated\n",
    "\n",
    "x = df.corr(numeric_only=True)\n",
    "columns_for_corr = [\"policy_amt\", \"csl_amt\", \"violent_rate\", \"non_violent_rate\", \"deaths_per_100k\", \"deaths_per_100mil_miles\", \"label\"]\n",
    "x.where((x > 0.5) & (x < 1)).loc[columns_for_corr, columns_for_corr].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_incident_severity</th>\n",
       "      <td>0.119142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non_violent_rate</th>\n",
       "      <td>0.096296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_vehicles_involved</th>\n",
       "      <td>0.078499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>violent_rate</th>\n",
       "      <td>0.072924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_state</th>\n",
       "      <td>0.070108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deaths_per_100k</th>\n",
       "      <td>0.055592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_insured_education_level</th>\n",
       "      <td>0.050458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>policy_amt</th>\n",
       "      <td>-0.049461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>umbrella_limit</th>\n",
       "      <td>0.049313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>csl_amt</th>\n",
       "      <td>-0.048822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incident_hour_of_the_day</th>\n",
       "      <td>0.040186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deaths_per_100mil_miles</th>\n",
       "      <td>0.036632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>witnesses</th>\n",
       "      <td>0.035485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bodily_injuries</th>\n",
       "      <td>0.028191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital_gains</th>\n",
       "      <td>-0.024975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_car_price</th>\n",
       "      <td>0.013819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital_loss</th>\n",
       "      <td>-0.013543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claim_capital_percent</th>\n",
       "      <td>0.003998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>months_as_customer</th>\n",
       "      <td>-0.003483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 label\n",
       "label                         1.000000\n",
       "rank_incident_severity        0.119142\n",
       "non_violent_rate              0.096296\n",
       "number_of_vehicles_involved   0.078499\n",
       "violent_rate                  0.072924\n",
       "in_state                      0.070108\n",
       "deaths_per_100k               0.055592\n",
       "rank_insured_education_level  0.050458\n",
       "policy_amt                   -0.049461\n",
       "umbrella_limit                0.049313\n",
       "csl_amt                      -0.048822\n",
       "incident_hour_of_the_day      0.040186\n",
       "deaths_per_100mil_miles       0.036632\n",
       "witnesses                     0.035485\n",
       "bodily_injuries               0.028191\n",
       "capital_gains                -0.024975\n",
       "avg_car_price                 0.013819\n",
       "capital_loss                 -0.013543\n",
       "claim_capital_percent         0.003998\n",
       "months_as_customer           -0.003483"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Because many are, only select the ones more correlated in abs to the label\n",
    "# ex. policy_amt and csl_amt are highly correlated and policy_amt is higher corr to take it\n",
    "\n",
    "x.loc[:, [\"label\"]].sort_values(\"label\", ascending=False, key=lambda x: abs(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(822, 21) (822,) (178, 21) (178,)\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"train_data.csv\")\n",
    "y_train = train_data[\"label\"]\n",
    "train_data.drop([\"label\"], axis=1, inplace=True)\n",
    "\n",
    "test_data = pd.read_csv(\"test_data.csv\")\n",
    "y_test = test_data[\"label\"]\n",
    "test_data.drop([\"label\"], axis=1, inplace=True)\n",
    "\n",
    "drop_by_corr = False\n",
    "if drop_by_corr:\n",
    "    for df in [train_data, test_data]:\n",
    "        df.drop([\"csl_amt\", \"deaths_per_100k\", \"violent_rate\"], axis=1, inplace=True)\n",
    "\n",
    "print(train_data.shape, y_train.shape, test_data.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runs without dropping by corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_cols = [\"insured_relationship\", \"authorities_contacted\"]\n",
    "scaler_cols = list(set(train_data.columns) - set(one_hot_cols))\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    [\n",
    "        (\"one_hot\", OneHotEncoder(), one_hot_cols),\n",
    "        (\"scaler\", StandardScaler(), scaler_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train = ct.fit_transform(train_data)\n",
    "feature_names = ct.get_feature_names_out(train_data.columns)\n",
    "X_test = ct.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_metrics(model, train=X_train, test=X_test):\n",
    "    train_preds = model.predict(train)\n",
    "    print(\"Train metrics\")\n",
    "    for name, metric in zip(['accuracy', 'auroc', 'f1'], [accuracy_score, roc_auc_score, f1_score]):\n",
    "        print(name, round(metric(y_train, train_preds), 3))\n",
    "\n",
    "    test_preds = model.predict(test)\n",
    "    print(\"\\nTest metrics\")\n",
    "    for name, metric in zip(['accuracy', 'auroc', 'f1'], [accuracy_score, roc_auc_score, f1_score]):\n",
    "        print(name, round(metric(y_test, test_preds), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "accuracy 0.617\n",
      "auroc 0.631\n",
      "f1 0.458\n",
      "\n",
      "Test metrics\n",
      "accuracy 0.545\n",
      "auroc 0.571\n",
      "f1 0.409\n"
     ]
    }
   ],
   "source": [
    "#class_weights = compute_class_weight(class_weight=\"balanced\", classes=[0, 1], y=y_train)\n",
    "lr = LogisticRegression(penalty=\"l2\", class_weight=\"balanced\", C=1, solver=\"liblinear\")\n",
    "lr.fit(X_train, y_train)\n",
    "importances = [(feature, round(exp(weight), 3)) for feature, weight in zip(feature_names, lr.coef_[0])]\n",
    "#sorted(importances, key=lambda y: -y[1])[:10]\n",
    "\n",
    "run_metrics(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "accuracy 0.837\n",
      "auroc 0.825\n",
      "f1 0.707\n",
      "\n",
      "Test metrics\n",
      "accuracy 0.747\n",
      "auroc 0.676\n",
      "f1 0.516\n"
     ]
    }
   ],
   "source": [
    "# Consider undoing one-hot encoding for decision tree\n",
    "dt = DecisionTreeClassifier(max_depth=5, class_weight=\"balanced\", random_state=653)\n",
    "dt.fit(X_train, y_train)\n",
    "importances = {feature: importance for feature, importance in zip(feature_names, dt.feature_importances_)}\n",
    "sorted_importances = sorted(list([x for x in importances.items() if x[1] > 0]), key=lambda y: -y[1])\n",
    "#sorted_importances\n",
    "run_metrics(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retry using importance and fewer features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rank_incident_severity', 'months_as_customer',\n",
       "       'incident_hour_of_the_day', 'witnesses', 'violent_rate',\n",
       "       'authorities_contacted', 'insured_relationship'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get down features\n",
    "#scaler_important_features = [feature[0].split(\"__\")[1] for feature in sorted_importances if not feature[0].startswith(\"one_hot\")][:7]\n",
    "scaler_important_features = [\"rank_incident_severity\", \"months_as_customer\", \"incident_hour_of_the_day\", \"witnesses\", \"violent_rate\"]\n",
    "cat_important_features = [\"authorities_contacted\", \"insured_relationship\"] # they appear in the list\n",
    "train_data_importance = train_data[scaler_important_features + cat_important_features]\n",
    "train_data_importance.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((178, 16), (178, 16))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct_importance = ColumnTransformer(\n",
    "    [\n",
    "        (\"one_hot\", OneHotEncoder(), cat_important_features), # don't need to encode for decision tree\n",
    "        (\"scaler\", StandardScaler(), scaler_important_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train_importance = ct_importance.fit_transform(train_data_importance)\n",
    "feature_names_importance = ct_importance.get_feature_names_out(train_data_importance.columns)\n",
    "\n",
    "test_data_importance = test_data[scaler_important_features + cat_important_features]\n",
    "X_test_importance = ct_importance.transform(test_data_importance)\n",
    "\n",
    "X_test_importance.shape, X_test_importance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# np.save(\"importance_train_data.npy\", X_train_importance)\n",
    "# np.save(\"importance_test_data.npy\", X_test_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "accuracy 0.586\n",
      "auroc 0.616\n",
      "f1 0.444\n",
      "\n",
      "Test metrics\n",
      "accuracy 0.573\n",
      "auroc 0.582\n",
      "f1 0.415\n"
     ]
    }
   ],
   "source": [
    "# Shows a benefit for logistic regression, train and test are close\n",
    "\n",
    "lr_importance = LogisticRegression(penalty=\"l1\", class_weight=\"balanced\", C=0.1, solver=\"liblinear\")\n",
    "lr_importance.fit(X_train_importance, y_train)\n",
    "run_metrics(lr_importance, X_train_importance, X_test_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "accuracy 0.81\n",
      "auroc 0.769\n",
      "f1 0.641\n",
      "\n",
      "Test metrics\n",
      "accuracy 0.815\n",
      "auroc 0.751\n",
      "f1 0.629\n"
     ]
    }
   ],
   "source": [
    "# Still better\n",
    "\n",
    "dt_importance = DecisionTreeClassifier(max_depth=2, class_weight=\"balanced\", random_state=653)\n",
    "dt_importance.fit(X_train_importance, y_train)\n",
    "run_metrics(dt_importance, X_train_importance, X_test_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import RFE, SequentialFeatureSelector\n",
    "# selector = SequentialFeatureSelector(lr)\n",
    "# selector = RFE(lr, n_features_to_select=10, step=1)\n",
    "# selector.fit(X_train, y_train)\n",
    "# print(selector.support_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf = RandomForestClassifier(bootstrap=True, class_weight=\"balanced\", random_state=653)\n",
    "# distributions=dict(max_depth=[2, 3, 4, 5], max_features=[\"sqrt\", 5, None]) \n",
    "# clf = GridSearchCV(rf, distributions, scoring=f1_score, verbose=0)\n",
    "# search = clf.fit(X_train, y_train)\n",
    "# search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "accuracy 0.82\n",
      "auroc 0.792\n",
      "f1 0.668\n",
      "\n",
      "Test metrics\n",
      "accuracy 0.815\n",
      "auroc 0.758\n",
      "f1 0.637\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(max_depth=4, max_features=5, bootstrap=True, class_weight=\"balanced\", random_state=653)\n",
    "rf.fit(X_train_importance, y_train)\n",
    "run_metrics(rf, X_train_importance, X_test_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 sqrt\n",
      "---------\n",
      "Train metrics\n",
      "accuracy 0.617\n",
      "auroc 0.691\n",
      "f1 0.518\n",
      "\n",
      "Test metrics\n",
      "accuracy 0.618\n",
      "auroc 0.663\n",
      "f1 0.5\n",
      "\n",
      "2 5\n",
      "---------\n",
      "Train metrics\n",
      "accuracy 0.605\n",
      "auroc 0.683\n",
      "f1 0.51\n",
      "\n",
      "Test metrics\n",
      "accuracy 0.618\n",
      "auroc 0.663\n",
      "f1 0.5\n",
      "\n",
      "2 None\n",
      "---------\n",
      "Train metrics\n",
      "accuracy 0.81\n",
      "auroc 0.769\n",
      "f1 0.641\n",
      "\n",
      "Test metrics\n",
      "accuracy 0.815\n",
      "auroc 0.751\n",
      "f1 0.629\n",
      "\n",
      "3 sqrt\n",
      "---------\n",
      "Train metrics\n",
      "accuracy 0.663\n",
      "auroc 0.718\n",
      "f1 0.547\n",
      "\n",
      "Test metrics\n",
      "accuracy 0.629\n",
      "auroc 0.664\n",
      "f1 0.5\n",
      "\n",
      "3 5\n",
      "---------\n",
      "Train metrics\n",
      "accuracy 0.707\n",
      "auroc 0.741\n",
      "f1 0.575\n",
      "\n",
      "Test metrics\n",
      "accuracy 0.691\n",
      "auroc 0.698\n",
      "f1 0.538\n",
      "\n",
      "3 None\n",
      "---------\n",
      "Train metrics\n",
      "accuracy 0.814\n",
      "auroc 0.776\n",
      "f1 0.65\n",
      "\n",
      "Test metrics\n",
      "accuracy 0.809\n",
      "auroc 0.747\n",
      "f1 0.622\n",
      "\n",
      "4 sqrt\n",
      "---------\n",
      "Train metrics\n",
      "accuracy 0.741\n",
      "auroc 0.761\n",
      "f1 0.603\n",
      "\n",
      "Test metrics\n",
      "accuracy 0.73\n",
      "auroc 0.717\n",
      "f1 0.564\n",
      "\n",
      "4 5\n",
      "---------\n",
      "Train metrics\n",
      "accuracy 0.82\n",
      "auroc 0.792\n",
      "f1 0.668\n",
      "\n",
      "Test metrics\n",
      "accuracy 0.815\n",
      "auroc 0.758\n",
      "f1 0.637\n",
      "\n",
      "4 None\n",
      "---------\n",
      "Train metrics\n",
      "accuracy 0.822\n",
      "auroc 0.787\n",
      "f1 0.665\n",
      "\n",
      "Test metrics\n",
      "accuracy 0.792\n",
      "auroc 0.714\n",
      "f1 0.575\n",
      "\n",
      "5 sqrt\n",
      "---------\n",
      "Train metrics\n",
      "accuracy 0.83\n",
      "auroc 0.817\n",
      "f1 0.696\n",
      "\n",
      "Test metrics\n",
      "accuracy 0.781\n",
      "auroc 0.721\n",
      "f1 0.581\n",
      "\n",
      "5 5\n",
      "---------\n",
      "Train metrics\n",
      "accuracy 0.827\n",
      "auroc 0.8\n",
      "f1 0.68\n",
      "\n",
      "Test metrics\n",
      "accuracy 0.809\n",
      "auroc 0.747\n",
      "f1 0.622\n",
      "\n",
      "5 None\n",
      "---------\n",
      "Train metrics\n",
      "accuracy 0.836\n",
      "auroc 0.811\n",
      "f1 0.695\n",
      "\n",
      "Test metrics\n",
      "accuracy 0.787\n",
      "auroc 0.71\n",
      "f1 0.568\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4 and 5 got the best score\n",
    "\n",
    "for depth in [2, 3, 4, 5]:\n",
    "    for num_f in [\"sqrt\", 5, None]:\n",
    "         print(depth, num_f)\n",
    "         print(\"---------\")\n",
    "         rf = RandomForestClassifier(max_depth=depth, max_features=num_f, bootstrap=True, class_weight=\"balanced\", random_state=653)\n",
    "         rf.fit(X_train_importance, y_train)\n",
    "         run_metrics(rf, X_train_importance, X_test_importance)\n",
    "         print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.87218045, 0.12781955],\n",
       "       [0.35555556, 0.64444444]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = rf.predict(X_test_importance)\n",
    "confusion_matrix(y_test, y_pred, labels=rf.classes_, normalize='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runs with dropping by corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train_data.csv\")\n",
    "y_train = train_data[\"label\"]\n",
    "train_data.drop([\"label\"], axis=1, inplace=True)\n",
    "\n",
    "test_data = pd.read_csv(\"test_data.csv\")\n",
    "y_test = test_data[\"label\"]\n",
    "test_data.drop([\"label\"], axis=1, inplace=True)\n",
    "\n",
    "drop_by_corr = True\n",
    "if drop_by_corr:\n",
    "    for df in [train_data, test_data]:\n",
    "        df.drop([\"csl_amt\", \"deaths_per_100k\", \"violent_rate\"], axis=1, inplace=True)\n",
    "\n",
    "print(train_data.shape, y_train.shape, test_data.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_cols = [\"insured_relationship\", \"authorities_contacted\"]\n",
    "scaler_cols = list(set(train_data.columns) - set(one_hot_cols))\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    [\n",
    "        (\"one_hot\", OneHotEncoder(), one_hot_cols),\n",
    "        (\"scaler\", StandardScaler(), scaler_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train = ct.fit_transform(train_data)\n",
    "feature_names = ct.get_feature_names_out(train_data.columns)\n",
    "X_test = ct.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('scaler__non_violent_rate', 1.469),\n",
       " ('one_hot__authorities_contacted_Other', 1.364),\n",
       " ('one_hot__insured_relationship_other-relative', 1.288),\n",
       " ('scaler__rank_incident_severity', 1.245),\n",
       " ('scaler__umbrella_limit', 1.162),\n",
       " ('one_hot__authorities_contacted_Ambulance', 1.144),\n",
       " ('one_hot__insured_relationship_not-in-family', 1.141),\n",
       " ('scaler__rank_insured_education_level', 1.106),\n",
       " ('scaler__in_state', 1.105),\n",
       " ('scaler__witnesses', 1.103)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#class_weights = compute_class_weight(class_weight=\"balanced\", classes=[0, 1], y=y_train)\n",
    "lr = LogisticRegression(penalty=\"l1\", class_weight=\"balanced\", C=10, solver=\"liblinear\")\n",
    "lr.fit(X_train, y_train)\n",
    "importances = [(feature, round(exp(weight), 3)) for feature, weight in zip(feature_names, lr.coef_[0])]\n",
    "sorted(importances, key=lambda y: -y[1])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "accuracy 0.616\n",
      "auroc 0.63\n",
      "f1 0.457\n",
      "\n",
      "Test metrics\n",
      "accuracy 0.556\n",
      "auroc 0.585\n",
      "f1 0.423\n"
     ]
    }
   ],
   "source": [
    "run_metrics(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('scaler__rank_incident_severity', 0.6340786820967172),\n",
       " ('scaler__witnesses', 0.0563592792156414),\n",
       " ('scaler__avg_car_price', 0.04995636508754498),\n",
       " ('scaler__capital_gains', 0.04614315130601874),\n",
       " ('scaler__deaths_per_100mil_vehicle_miles', 0.045277065273033636),\n",
       " ('scaler__umbrella_limit', 0.038127125255876505),\n",
       " ('scaler__claim_capital_percent', 0.03627865915872157),\n",
       " ('scaler__months_as_customer', 0.031300575903479004),\n",
       " ('scaler__incident_hour_of_the_day', 0.02867029332903156),\n",
       " ('scaler__non_violent_rate', 0.022622122801992783),\n",
       " ('scaler__rank_insured_education_level', 0.011186680571942739)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Consider undoing one-hot encoding for decision tree\n",
    "dt = DecisionTreeClassifier(class_weight=\"balanced\", max_depth=5)\n",
    "dt.fit(X_train, y_train)\n",
    "importances = {feature: importance for feature, importance in zip(feature_names, dt.feature_importances_)}\n",
    "sorted(list([x for x in importances.items() if x[1] > 0]), key=lambda y: -y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics\n",
      "accuracy 0.82\n",
      "auroc 0.821\n",
      "f1 0.692\n",
      "\n",
      "Test metrics\n",
      "accuracy 0.747\n",
      "auroc 0.684\n",
      "f1 0.526\n"
     ]
    }
   ],
   "source": [
    "run_metrics(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imbalanced learning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp653",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
